import torch

print("âœ… PyTorch æ£€æŸ¥å¼€å§‹...\n")

print(f"ğŸ§  å½“å‰ PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ” æ˜¯å¦æ”¯æŒ CUDAï¼ˆGPUï¼‰: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"ğŸš€ å¯ç”¨ GPU æ•°é‡: {torch.cuda.device_count()}")
    print(f"ğŸ’» å½“å‰ GPU åç§°: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ“Š å½“å‰ CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"ğŸ“¦ å½“å‰è®¾å¤‡: {torch.cuda.current_device()} (Index)")
else:
    print("âŒ å½“å‰æœªæ£€æµ‹åˆ°å¯ç”¨çš„ CUDA GPUã€‚è¯·æ£€æŸ¥é©±åŠ¨ / PyTorch å®‰è£…æ˜¯å¦æ­£ç¡®ã€‚")
